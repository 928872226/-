# 编程真的是一个细心活zz
# 多线程下载表情包
import threading
import requests
from lxml impot etree
from urllib import request
import os 
import re
from queue import Queue
class Producter(threading.Thread)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'
    }
    def __init__(self,page_queue,img_queue,*args,**kwargs):
    super(Producter, self).__init__(*args,**kwargs)
    self.page_queue = page_queue
    self.img_queue = img_queue
    def run(self):
        while True:
            if self.page_queue.empty():
                break
            url = self.page_queue.get()
            self.parse_page(url)
     def parse_page(self,url):
         reponse = requests.get(url,headers = self.headers)
         text = response.text
         html = etree.HTML(text)
         imgs = html.xpath("//div[@class='page-content text-center']//a//img")
         for img in imgs:
             if img.get('class') == 'gif':
                 cintinue
             img_url = img.xpath(".//@data-original")[0]
             suffix = os.path.splitext(img_url)[1]
             alt = img.xpath(".//@data-original")[0]
             alt = re.sub(r'[，。？?,/\\·]','',alt)
             img_name = alt + suffix
             self,img_queue.put((img_url,img_name))
 class Consumer(threading.Thread):
     def __init__(self,page_queue,img_queue,*args,**kwargs):
         super(Consumer, self).__init__(*args,**kwargs)
         self.page_queue = page_queue
         self.img_queue = img_queue
     def run(self):
         while True:
             if self.img_queue.empty():
                 if self.page_queue.empty(）:
                     return
             img = self.img_queue.get(block=True)
             url,filename = img
             request.urlretrieve(url,'123/'+filename)
             print(filename+'下载完成！！！')
  def main():
      page_queue = Queue(100)
      img_queue = Queue(10000)
      for x in range(1,101)
          url = 'http://www.doutula.com/photo/list/?page=%d' % x
          page_queue.put(url)
      for x in range(5):
          t = Producter(page_queue,img_queue)
          t.start()
      for x in range(5):
          t = Consumer(page_queue,img_queue)
          t.start()
  main
      main(）
  # 以上是多线程下载表情包
  # 昨天去看了土星，在操场跑了两圈zz
  # 多线程下载百思不得姐段子作业
  import requests
  from lxml import etree
  import threading
  import threading
  from queue import Queue
  import csv
  class BSSpider(threading.Thread):
      headers = {
          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'
      }
      def __init__(self,page_queue,joke_queue,*args,**kwargs):
          super(BSSpider, self).__init__(*args,**kwargs)
          self.base_domain = 'http://www.budejie.com'
          self.page_queue = page_queue
          self.joke_queue = joke_queue
      def run(self):
           while True:
               if self.page_queue.empty():
                   break
               url = self.page_queue.empty():
               respongse = requests.get(url,headers = self.headers)
               text = response.text
               html = etree.HTML(text)
               descs = html.xpath("//div[@class='j-r-list-c-desc']"
               for desc in descs:
                   jokes = desc.xpath(".//text()")
                   joke = "\n".join(jokes).strip()
                   link = self.base_domain+desc.xpath(".//a/@href")[0]
                   self.joke_queue.put((joke,link))
               print('='*30+"第%s页下载完成!"% url.split('/')[-1]+"="*30
   class BSWriter(threading.Thread):
       headers = {
           'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'
       }
       def __init__(self, joke_queue, writer,gLock, *args, **kwargs):
           super(BSWriter, self).__init__(*args, **kwargs)
           self.joke_queue = joke_queue
           self.writer = writer
           self.lock = gLock
       def run(self):
           while True:
               try:
                   joke_info = self.joke_queue.get(timeout=40)
                   joke,link = joke_info
                   self.lock.acquire()
                   self.writer.writerow((joke,link))
                   self.lock.release()
                   print('保存一条')
               except:
                   break
       def main():
           page_queue = Queue(10)
           joke_queue = Queue(500)
           gLock = threading.Lock()
           fp = open('bsbdj.csv','a',newline='',encoding = 'utf-8')
           writer = csv.writer(fp)
           writer.writerow(('content','linl'))
           for x in range(1,11):
               url = 'http://www.budejie.com/text/%d' % x
               page_queue.put(url)
           for x in range(5):
               t = BSSpider(page_queue,joke_queue)
               t.start()
           for x in range(5):
               t = BSWriter(joke_queue,writer,gLock)
               t.start()
   main
       main()
              
           
                  
               
                   
       


    
            
                 
    
             
         

# 正则表达式匹配多个字符
*：可以匹配0或者任意多个字符
text = "0731"
ret = re.match('\d*',text)
print(ret.group())

+:可以匹配1个或者多个字符，最少一个
text = "abc"
ret = re.match('\w+',text)
print(ret.group())

?:匹配的字符可以出现一次或者不出现（0或者1）
text = "123"
ret = re.match('\d?',text)
print(ret.group())

{m}:匹配m个字符
text = "123"
ret = re.match('\d{2}',text)
print(ret.group())

{m,n}:匹配m-n个字符，在这中间的字符都可以匹配到
text = "123"
ret = re.match('\d{1,2}',text)
print(ret.group())

# 小案例
验证手机号码：手机号码的规则是以1开头，第二位可以是34587，后面9位可以随意
text = "13280009120"
ret = re.match('1[34587]\d{9}',text)
print(ret.group()）

验证邮箱：邮箱的规则是邮箱名称是用数字、字母、下划线组成，然后是@符号，后面就是域名了
text = "928872226@qq.com"
ret = re.match('\d+@\w+\.[a-zA-Z\.]+',text)
print(ret.group())

验证URL：URL的规则是前面是http,https,ftp然后再加上：，再加上//，后面就是任意非空白字符了
text = "http:www.baidu.com"
ret = re.match('(http|https|ftp)://[^\s]+',text)
print(ret.group())

验证身份证：身份证的规则是总共18位，前17位都是数字，后面1位可以是数字、x、X
text = "370123199511043411"
ret = re.match('\d{17}[\dxX]',text)
print(ret.group())

^:表示以...开始
text = "hello"
ret = re.match('^h',text)
print(ret.group())

$:表示以...结束
text = 928872226@qq.com"
ret = re.match('\w+@\w+\.com$',text)
peint(ret.group())

|:匹配多个表达式或者字符串
text = "hello| world"
ret = re.search('hello',text)
print(ret.group())

贪婪模式和非贪婪模式
贪婪模式：正则表达式会匹配尽量多的字符，默认是贪婪模式
非贪婪模式：正则表达式会尽量少的匹配字符
text = "012345"
ret = re.match('\d+',text)
print(ret.group())
改成非贪婪模式，那么就只会匹配到0
text = "012345"
ret = re.match('\d+?',text)
print(ret.group())

案例：匹配0-100之间的数字
text = "99"
ret = re.match('[1-9]?\d$|100$',text)
print(ret.group())

转义字符和原生字符串
在正则表达式中，有些字符是有特殊意义的字符，因此如果想要匹配这些字符，就必须使用反斜杠进行转义
text = "apple price is $99 orange price is $88"
ret = re.search('\$\d+',text)
print(ret.group())
原生字符串：在正则表达式中，\是专门用来做转义的，在python中\也是用来做转义的，因此如果想要在普通字符串中匹配出\，那么要给出四个\\\\
text = "apple \c"
ret = re.search('\\\\c',text)
print(ret.group()）
因此要使用原生字符串就可以解决这个问题
text = "apple \c"
ret = re.search(r'\\c',text)
print(ret.group())

# re模块中常用的函数
match:从开始的位置进行匹配，如果开始的位置没有匹配到，失败
text = "hello"
ret = re.match('h',text)
print(ret.group())

search:在字符串中找满足条件的字符，如果找到就返回，说白了只会找到第一个满足条件的
text = "apple price $99 orange price &88"
ret = re.search('\d+',text)
print(ret.group())

分组：在正则表达式中，可以对过滤到的字符串进行分组，分组使用圆括号的方式
1.group:返回的是整个满足条件的字符串
2.groups：返回的是里面的子组，索引从1开始
3.group(1):返回的是第一个子组，可以传入多个
text = "apple price is $99 orange price is $10"
ret = re.match(r'.*(\$\d+).*(\$\d+)',text)
print(ret.group(())
print(ret.group(0))
print(ret.groups())
print(ret.group(2))

findall:找出所有满足条件的，返回的是一个列表
text = "apple price $99 orange price $88"
ret = re.findall('\d+',text)
print(ret.group()）

sub:用来替换字符串，将匹配到的字符串替换为其他字符串
text = "apple price $99 orange price $88"
ret = re.sub('\d','0',text)
print(ret)

split:使用正则表达式来分割字符串
text = "hello world ni hao"
ret = re.split('\w',text)
print(ret)

compile:对正则表达式进行编译，后期使用时可以直接拿来用
text = "the number is 20.50"
r = re.compile(r'\d+\.?\d*',text)
ret = re.search(r.text)
print(ret.group())

爬虫实战：爬取中国古诗文网
import requests
import re
def parse_page(url):
    hesders = {
        "User-Agent":"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36"
    }
    response = requests.get(url,headers)
    text = response.text
    titles = re.findall(r'<div\sclass="cont">.*?<b>(.*?)</b>',text,re.DOTALL)
    dynasties = re.findall(r'<p class="source">.*?<a.*?>(.*?)</a>',text,re.DOTALL)
    authors = re.findall(r'<p class="source">.*?<a.*?>.*?<a.*?>(.*?)</a>',text,re.DOTALL)
    content_tags = re.findall(r'<div class="contson".*?>(.*?)</div>',text,re.DOTALL）
    contents = []
    for content in content_tags:
        x = re.sub(r'<.*?>',"",content)
        contents.append(x.strip())
    poems = []
    for value in zip(titles,dynasties,authors,contents)
        title,dynastie,author,content = value
        poem = {
            'title':title,
            'dynastie':dynastie,
            'author':author,
            'content':content
            }
            poems.append(poem)
        for poem in poems:
            print(poem)
    def main()
        for x in range(1,11):
            url = 'https://www.gushiwen.org/default_%s.aspx'% x
            parse_page(url)
    main
        main()
  
 # 以上为昨天所学正则表达式内容，到此爬虫已经学习了进一半了，首先进行网络请求，其次进行数据提取。加油↖(^ω^)↗
 昨天去跑步了
 努力提升自己，当自己可以发光的时候，自然不惧黑暗，而且会有人借你的微光取暖，加油学习这东西贵在坚持。相信厚积薄发^_^
 期待新的一天！！！！




